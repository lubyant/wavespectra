"""Read SWAN spectra files.

Functions:
    read_spotter: Read Spectra from Spotter JSON file
    read_spotters: Read multiple spotter files into single Dataset

"""
from xarray.backends import BackendEntrypoint
import types
from pathlib import Path
import glob
import os
import getpass
from datetime import datetime, timezone
import json
import numpy as np
import xarray as xr
import pandas as pd
from dateutil.parser import parse

import wavespectra
from wavespectra.core.attributes import attrs, set_spec_attributes
from wavespectra.construct.direction import cartwright


PARAMETERS_CSV = {
    "Battery Voltage": "batt_volt",
    "Power": "power",
    "Humidity": "humidity",
    "Epoch Time": "time",
    "Significant Wave Height": "hs",
    "Peak Period": "tp",
    "Mean Period": "tm",
    "Peak Direction": "dpm",
    "Peak Directional Spread": "dpspr",
    "Mean Direction": "dm",
    "Mean Directional Spread": "dspr",
    "Latitude": "lat",
    "Longitude": "lon",
    "Wind Speed": "wspd",
    "Wind Direction": "wdir",
    "Surface Temperature": "sst",
}

SPECTRAL_CSV = {
    "varianceDensity": "efth",
    "direction": "dmf",
    "directionalSpread": "dsprf",
    "a1": "a1",
    "b1": "b1",
    "a2": "a2",
    "b2": "b2",
}


def read_spotter(filename, filetype=None):
    """Read Spectra from Spotter file.

    Args:
        - filename (list, str): File name or file glob specifying spotter files to read.
        - filetype (str): 'json' or 'csv', if not passed inferred from filename.

    Returns:
        - dset (SpecDataset): spectra dataset object read from file.

    """

    if filename is not isinstance(filename, list):
        filename = [filename]

    if filetype is None:
        filetype = os.path.splitext(filename[0])[1]

    filetype = filetype.removeprefix(".").lower()

    if filetype == "json":
        return _read_spotter_json(filename)
    elif filetype == "csv":
        dslist = []
        for fn in filename:
            dslist.append(_read_spotter_csv(fn))
        return xr.concat(dslist, dim="time")
    else:
        raise ValueError(f"filetype='{filetype}', must be either 'json' or 'csv' ")


class SpotterCSV:

    def __init__(self, filename):
        """Read Spectra from Spotter CSV file.

        Args:
            - filename (str): File name specifying spotter file to read.

        """
        self.filename = filename

    @property
    def cols(self) -> list:
        """Header columns."""
        return [c.split("(")[0].strip() for c in pd.read_csv(self.filename, nrows=0)]

    @property
    def freq(self) -> xr.DataArray:
        """Frequency array."""
        data = pd.read_csv(self.filename, usecols=self._usecols("f_"))
        data = data.drop_duplicates()
        if data.shape[0] > 1:
            raise NotImplementedError(
                "Varying frequency arrays in single file not yet supported."
            )
        data = data.values[0]
        return xr.DataArray(data, coords=dict(freq=data), name="freq")

    @property
    def time(self) -> xr.DataArray:
        """Times."""
        data = self._set_header(pd.read_csv(self.filename, usecols=self._usecols("Epoch")))
        data = data.rename(columns={"Epoch Time": "time"}).set_index("time")
        data.index = pd.to_datetime(data.index, unit="s")
        return xr.DataArray(data.index, coords=dict(time=data.index), name="time")

    def _set_header(self, df: pd.DataFrame) -> pd.DataFrame:
        """Remove units and trailling spaces from column names."""
        df.columns = [c.split("(")[0].strip() for c in df.columns]
        return df

    def _usecols(self, prefix: str) -> list:
        """Return the indices of all columns that start with the prefix."""
        return [ind for ind, val in enumerate(self.cols) if val.startswith(prefix)]

    def _read_spectral_data(self, prefix: str, coords: dict) -> xr.DataArray:
        data = pd.read_csv(self.filename, usecols=self._usecols(prefix))
        return xr.DataArray(data, coords=coords)

    def _set_attributes(self, dset: xr.Dataset) -> xr.Dataset:
        set_spec_attributes(dset)
        dset.attrs = {
            "title": f"Spotter buoy spectral data from {Path(self.filename).name}",
            "source": "Spotter wave buoy",
            "history": f"Generated by wavespectra v{wavespectra.__version__}",
            "date_created": f"{datetime.now(timezone.utc)}",
            "creator_name": getpass.getuser(),
            "references": "https://content.sofarocean.com/hubfs/Technical_Reference_Manual.pdf",
        }
        return dset

    def read_spectra(self) -> xr.Dataset:
        """Read spectral data"""
        dset = xr.Dataset()
        coords = {"time": self.time, "freq": self.freq}
        for var in SPECTRAL_CSV.keys():
            dset[var] = self._read_spectral_data(var + "_", coords)
        return dset.rename(SPECTRAL_CSV)

    def read_params(self) -> xr.Dataset:
        """Read bulk parameters."""
        usecols = [ind for ind, val in enumerate(self.cols) if val in PARAMETERS_CSV]
        data = pd.read_csv(self.filename, usecols=usecols)
        data = self._set_header(data).rename(columns=PARAMETERS_CSV)
        data = data.set_index("time")
        data.index = pd.to_datetime(data.index, unit="s")
        return data.to_xarray()

    def read(self, dd: float = None) -> xr.Dataset:
        """Read spotter file as wavespectra dataset.

        Args:
            - dd (float): Directional spacing if 2D spectra are desired.

        Returns:
            - dset (SpecDataset): wavespectra dataset object.

        """
        dset = xr.merge([self.read_spectra(), self.read_params()])
        dset = dset.sortby("time")
        if dd is not None:
            dir = np.arange(0, 360, dd)
            dir = xr.DataArray(dir, coords=dict(dir=dir), name="dir")
            cos2 = cartwright(dir=dir, dm=dset.dmf, dspr=dset.dsprf)
            dset["efth"] = dset.efth * cos2
        set_spec_attributes(dset)
        return self._set_attributes(dset).sortby("time")


def _read_spotter_csv(filename):
    """Read Spectra from Spotter CSV file."""
    spot = SpotterCSV(filename)
    dset = spot.read(dd=2)
    return dset


def _read_spotter_json(filename):
    """Read Spectra from Spotter JSON file.

    Args:
        - filename (list, str): File name or file glob specifying spotter files to read.

    Returns:
        - dset (SpecDataset): spectra dataset object read from file.

    """
    spot = Spotter(filename)
    dset = spot.run()
    return dset


class Spotter:
    def __init__(self, filename_or_fileglob, toff=0):
        """Read wave spectra file from TRIAXYS buoy.

        Args:
            - filename_or_fileglob (str, list): filename or fileglob
              specifying files to read.
            - toff (float): time offset in hours to account for
              time zone differences.

        Returns:
            - dset (SpecDataset) wavespectra SpecDataset instance.

        Remark:
            - frequencies and directions from first file are used as reference
              to interpolate spectra from other files in case they differ.
              In fact interpolation is still not implemented here, code will break
              if spectral coordinates are different.

        """
        self._filename_or_fileglob = filename_or_fileglob
        self.toff = toff

    def run(self):
        """Returns wave spectra dataset from one or more spotter files."""
        dsets = []
        for self.filename in self.filenames:
            self._load_json()
            self._set_arrays_from_json()
            dsets.append(self._construct_dataset())
        # Ensure same spectral coords across files, interp needs to be implemented
        if not self._is_unique([dset.freq.values for dset in dsets]):
            raise NotImplementedError(
                "Varying frequency arrays between spotter files not yet supported."
            )
        # Concatenating datasets from multiple files
        self.dset = xr.concat(dsets, dim="time")
        return self.dset

    def _is_unique(self, arrays):
        """Returns True if all iterators in arrays are the same."""
        if len(set(tuple(array) for array in arrays)) == 1:
            return True
        else:
            return False

    def _set_arrays_from_json(self):
        """Set spectra attributes from arrays in json blob."""
        # Spectra
        keys = self.data["data"]["frequencyData"][0].keys()
        for key in keys:
            setattr(
                self,
                key,
                [sample[key] for sample in self.data["data"]["frequencyData"]],
            )
        # Keep here only for checking - timestamps seem to differ
        self.timestamp_spec = self.timestamp
        self.latitude_spec = self.latitude
        self.longitude_spec = self.longitude
        # Parameters
        if "waves" in self.data["data"]:
            keys = self.data["data"]["waves"][0].keys()
            for key in keys:
                setattr(
                    self, key, [sample[key] for sample in self.data["data"]["waves"]]
                )
        # Keep here only for checking - timestamps seem to differ
        self.timestamp_param = self.timestamp
        self.latitude_param = self.latitude
        self.longitude_param = self.longitude

    def _construct_dataset(self):
        """Construct wavespectra dataset."""
        self.dset = xr.Dataset()
        # Spectral data
        self.dset["efth"] = xr.DataArray(self.varianceDensity, coords=self.coords2)
        # Time-varying cordinates
        self.dset[attrs.LATNAME] = xr.DataArray(self.latitude, coords=self.coords1)
        self.dset[attrs.LONNAME] = xr.DataArray(self.longitude, coords=self.coords1)
        # Directional parameters
        self.dset["dmf"] = xr.DataArray(self.direction, coords=self.coords2)
        self.dset["dsprf"] = xr.DataArray(self.directionalSpread, coords=self.coords2)
        # Bulk parameters
        for name, var in self.params.items():
            if hasattr(self, name):
                self.dset[var] = xr.DataArray(getattr(self, name), coords=self.coords1)
        set_spec_attributes(self.dset)
        return self.dset

    def _load_json(self):
        """Load data from json blob."""
        with open(self.filename) as json_file:
            self.data = json.load(json_file)
        try:
            self.data["data"]["spotterId"]
        except KeyError:
            raise OSError(f"Not a Spotter Spectra file: {self.filename}")

    @property
    def params(self):
        """Mapping of spotter to wavespectra bulk parameters."""
        return {
            "significantWaveHeight": "hs",
            "peakPeriod": "tp",
            "meanPeriod": "tm",
            "peakDirection": "dpm",
            "peakDirectionalSpread": "dpspr",
            "meanDirection": "dm",
            "meanDirectionalSpread": "dspr",
        }

    @property
    def time(self):
        """The time coordinate values."""
        return [
            parse(time).replace(tzinfo=None) - datetime.timedelta(hours=self.toff)
            for time in self.timestamp
        ]

    @property
    def freq(self):
        """The frequency coordinate values."""
        if not self._is_unique(self.frequency):
            raise NotImplementedError(
                "Varying frequency arrays in single file not yet supported."
            )
        return self.frequency[0]

    @property
    def dir(self):
        """The direction coordinate values, currently set to [0.] for 1D spectra."""
        return [0.0]

    @property
    def coords1(self):
        """The dataset coordinates for timeseries."""
        return {attrs.TIMENAME: self.time}

    @property
    def coords2(self):
        """The dataset coordinates for spectra."""
        return {attrs.TIMENAME: self.time, attrs.FREQNAME: self.freq}

    @property
    def filenames(self):
        if isinstance(self._filename_or_fileglob, list):
            filenames = sorted(self._filename_or_fileglob)
        elif isinstance(self._filename_or_fileglob, str):
            filenames = sorted(glob.glob(self._filename_or_fileglob))
        elif isinstance(self._filename_or_fileglob, types.GeneratorType):
            filenames = sorted(self._filename_or_fileglob)
        elif isinstance(self._filename_or_fileglob, Path):
            filenames = sorted(glob.glob(str(self._filename_or_fileglob)))
        if not filenames:
            raise ValueError(f"No file located in {self._filename_or_fileglob}")
        return filenames


class SpotterBackendEntrypoint(BackendEntrypoint):
    """Spotter backend engine."""

    def open_dataset(
        self,
        filename_or_obj,
        *,
        drop_variables=None,
        filetype=None,
    ):
        return read_spotter(filename_or_obj, filetype=filetype)

    def guess_can_open(self, filename_or_obj):
        return False

    description = "Open Spotter spectra files as a wavespectra dataset."

    url = "https://github.com/wavespectra/wavespectra"
